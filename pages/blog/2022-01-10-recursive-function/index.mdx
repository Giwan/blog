import Article from "../../../components/Article/Article";

export const description =
    "Loop over an array with a recursive function. In this case the array entry has a URL that should be validated before moving on to the next";

export const meta = {
    title: "Recursive JS function",
    description,
    createdDate: "2022-01-10",
    published: "2022-01-10",
    readTime: 2,
};

export default ({ children }) => <Article {...{meta}}>{children}</Article>

Validating a long list of websites can take a lot of time. In addition, it's not clear how much time is required to load the details of a given site. 
This simple post, looks at the approach taken to solve the issue. 

Starting with a list of sites to validate, each site is checked individually. 

```javascript

const sites = [
    "https://mytoori.com",
    "https://bbc.co.uk",
    "https://news.ycombinator.com/",
]

const validateXFrameHeaders = function(headers) {
    // do some validation and return boolean
    const hasXFrameOptions = headers["X-Frame-options"];
    if (hasXFrameOptions && ["deny", "sameorigin"].includes(hasXFrameOptions.toLowerCase())) {
        console.log('blocks iframe through x-frame-options');
    }

    return true; // for the sake of the example
}

// loop over the three sites using a recursive function
let i = 0;
const recurisveLoop = async function() {
    // stop the loop if the end has been reached
    if (i >= sites.length) {
        console.log(`Finished looping over ${sites.length} sites`);
        return;
    }

    const site = sites[i]; // get the current site
    const data = await fetch(site);

    // validation (this is very crude for the sake of the example)
    validateXFrameHeaders(data.headers); // the result is being ignored
    
    // continue with the next iteration
    i += 1; 
    recursiveLoop();
}
recursiveLoop(); // start the loop
```

The benefit of this is that it doesn't matter how long it takes to get the data back from the site. 
The loop will only continue once that information has been received. 

If any of the sites go over a certain amount of time the request will timeout and the loop will continue. 
If that wait time needs to be shortened then a `setTimeout` call can be used. 